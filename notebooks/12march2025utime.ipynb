{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from lib.utils import get_dataloader\n",
    "from lib.utils import SleepStageClassifier\n",
    "from lib.utils import ekyn_ids,snezana_mice_ids,courtney_ids\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,classification_report\n",
    "from lib.utils import calculate_f1,plot_training_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekyn_ids = ekyn_ids[:8]\n",
    "snezana_mice_ids = snezana_mice_ids[:8]\n",
    "courtney_ids = courtney_ids[:8]\n",
    "print(ekyn_ids,snezana_mice_ids,courtney_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ekyn_ids,test_ekyn_ids = ekyn_ids[:-len(ekyn_ids)//4],ekyn_ids[-len(ekyn_ids)//4:]\n",
    "print(len(train_ekyn_ids),len(test_ekyn_ids),train_ekyn_ids,test_ekyn_ids)\n",
    "train_snezana_mice_ids,test_snezana_mice_ids = snezana_mice_ids[:-len(snezana_mice_ids)//4],snezana_mice_ids[-len(snezana_mice_ids)//4:]\n",
    "print(len(train_snezana_mice_ids),len(test_snezana_mice_ids),train_snezana_mice_ids,test_snezana_mice_ids)\n",
    "train_courtney_ids,test_courtney_ids = courtney_ids[:-len(courtney_ids)//4],courtney_ids[-len(courtney_ids)//4:]\n",
    "print(len(train_courtney_ids),len(test_courtney_ids),train_courtney_ids,test_courtney_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader = get_dataloader(train_ekyn_ids[:1],snezana_mice_ids=None,courtney_ids=None,batch_size=batch_size,shuffle=True,downsample=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SleepStageClassifier()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, dilation=1, padding='same'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if padding == 'same':\n",
    "            padding = ((kernel_size - 1) * dilation) // 2\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class UTime(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=5, base_filters=16, segment_length=3000):\n",
    "        super(UTime, self).__init__()\n",
    "        self.segment_length = segment_length\n",
    "\n",
    "        # Encoder with adjusted padding to preserve length where possible\n",
    "        self.enc1 = ConvBlock(in_channels, base_filters, dilation=2)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=10, padding=0)  # No padding here, adjust input if needed\n",
    "        self.enc2 = ConvBlock(base_filters, base_filters * 2, dilation=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=8)\n",
    "        self.enc3 = ConvBlock(base_filters * 2, base_filters * 4, dilation=2)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=6)\n",
    "        self.enc4 = ConvBlock(base_filters * 4, base_filters * 8, dilation=2)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=4)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock(base_filters * 8, base_filters * 16, dilation=2)\n",
    "\n",
    "        # Decoder\n",
    "        self.up4 = nn.Upsample(scale_factor=4, mode='nearest')\n",
    "        self.dec4 = ConvBlock(base_filters * 24, base_filters * 8, kernel_size=4, dilation=1)\n",
    "        self.up3 = nn.Upsample(scale_factor=6, mode='nearest')\n",
    "        self.dec3 = ConvBlock(base_filters * 12, base_filters * 4, kernel_size=6, dilation=1)\n",
    "        self.up2 = nn.Upsample(scale_factor=8, mode='nearest')\n",
    "        self.dec2 = ConvBlock(base_filters * 6, base_filters * 2, kernel_size=8, dilation=1)\n",
    "        self.up1 = nn.Upsample(scale_factor=10, mode='nearest')\n",
    "        self.dec1 = ConvBlock(base_filters * 3, base_filters, kernel_size=10, dilation=1)\n",
    "\n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv1d(base_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        # Segment Classifier\n",
    "        self.segment_classifier = nn.Sequential(\n",
    "            nn.AvgPool1d(kernel_size=segment_length, stride=segment_length),\n",
    "            nn.Conv1d(num_classes, num_classes, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_length = x.size(2)  # Preserve input length\n",
    "\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "        e4 = self.enc4(p3)\n",
    "        p4 = self.pool4(e4)\n",
    "        bottleneck = self.bottleneck(p4)\n",
    "\n",
    "        # Decoder with length preservation\n",
    "        d4 = self.up4(bottleneck)\n",
    "        d4 = torch.cat([d4, F.interpolate(e4, size=d4.size(2), mode='nearest')], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat([d3, F.interpolate(e3, size=d3.size(2), mode='nearest')], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, F.interpolate(e2, size=d2.size(2), mode='nearest')], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat([d1, F.interpolate(e1, size=d1.size(2), mode='nearest')], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        # Adjust output to match input length\n",
    "        sample_scores = self.final_conv(d1)\n",
    "        if sample_scores.size(2) != input_length:\n",
    "            sample_scores = F.interpolate(sample_scores, size=input_length, mode='nearest')\n",
    "\n",
    "        segment_scores = self.segment_classifier(sample_scores)\n",
    "\n",
    "        return sample_scores, segment_scores\n",
    "\n",
    "# Test the updated model\n",
    "batch_size = 2\n",
    "channels = 1\n",
    "time_steps = 45000\n",
    "num_classes = 3\n",
    "segment_length = 5000\n",
    "\n",
    "model = UTime(in_channels=channels, num_classes=num_classes, segment_length=segment_length)\n",
    "x = torch.randn(batch_size, channels, time_steps)\n",
    "sample_scores, segment_scores = model(x)\n",
    "\n",
    "print(\"Sample scores shape:\", sample_scores.shape)  # Should be [2, 5, 105000]\n",
    "print(\"Segment scores shape:\", segment_scores.shape)  # Should be [2, 5, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = F.softmax(pred, dim=1)  # Convert to probabilities\n",
    "        intersection = (pred * target).sum(dim=(0, 2))\n",
    "        union = pred.sum(dim=(0, 2)) + target.sum(dim=(0, 2))\n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice.mean()  # Average over classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import load_ekyn\n",
    "id = train_ekyn_ids[0]\n",
    "condition = 'PF'\n",
    "X,y = load_ekyn(id=id,condition=condition)\n",
    "X = X.unfold(dimension=0,size=9,step=1)\n",
    "X = X.flatten(1,2)\n",
    "X = X.unsqueeze(1)\n",
    "y = y.unfold(dimension=0,size=9,step=1)\n",
    "trainloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y), batch_size=32, shuffle=True)\n",
    "\n",
    "# Example training loop (pseudo-code)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = DiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "lossi = []\n",
    "# Assuming target is one-hot encoded with shape (batch_size, num_classes, num_segments)\n",
    "for epoch in range(1):\n",
    "    for Xi,yi in tqdm(trainloader):\n",
    "        Xi,yi = Xi.to(device),yi.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        _, segment_scores = model(Xi)\n",
    "        loss = criterion(segment_scores, yi)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import load_ekyn\n",
    "id = train_ekyn_ids[1]\n",
    "condition = 'Vehicle'\n",
    "X,y = load_ekyn(id=id,condition=condition)\n",
    "X = X.unfold(dimension=0,size=9,step=1)\n",
    "X = X.flatten(1,2)\n",
    "X = X.unsqueeze(1)\n",
    "y = y.unfold(dimension=0,size=9,step=1)\n",
    "testloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y), batch_size=32, shuffle=True)\n",
    "\n",
    "model.cpu()\n",
    "Xi,yi = next(iter(testloader))\n",
    "_, segment_scores = model(Xi)\n",
    "segment_scores = F.softmax(segment_scores, dim=1)\n",
    "y_pred = segment_scores.argmax(dim=1).view(-1)\n",
    "y_true = yi.argmax(dim=1).view(-1)\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = segment_scores.argmax(dim=1)[0]\n",
    "y_true= yi.argmax(dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 2\n",
    "channels = 1\n",
    "time_steps = 105000  # 17.5 minutes at 100 Hz (35 segments of 30s)\n",
    "num_classes = 3\n",
    "\n",
    "# Create model\n",
    "model = UTime(in_channels=channels, num_classes=num_classes, segment_length=segment_length)\n",
    "\n",
    "# Sample input (batch_size, channels, time_steps)\n",
    "x = torch.randn(batch_size, channels, time_steps)\n",
    "\n",
    "# Forward pass\n",
    "sample_scores, segment_scores = model(x)\n",
    "\n",
    "print(\"Sample scores shape:\", sample_scores.shape)  # Expected: (2, 5, 105000)\n",
    "print(\"Segment scores shape:\", segment_scores.shape)  # Expected: (2, 5, 35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
