{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import TensorDataset,ConcatDataset,DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn.functional import relu\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = 'cuda'\n",
    "conditions = ['PF','Vehicle']\n",
    "path_to_pt_ekyn = f'../pt_ekyn'\n",
    "path_to_pt_snezana_mice = f'../pt_snezana_mice'\n",
    "\n",
    "ekyn_ids = sorted(set([recording_filename.split('_')[0] for recording_filename in os.listdir(path_to_pt_ekyn)]))\n",
    "snezana_mice_ids = sorted(set([recording_filename.split('.')[0] for recording_filename in os.listdir(path_to_pt_snezana_mice)]))\n",
    "print(len(ekyn_ids),ekyn_ids)\n",
    "print(len(snezana_mice_ids),snezana_mice_ids)\n",
    "\n",
    "def load_ekyn(id,condition):\n",
    "    X,y = torch.load(f'{path_to_pt_ekyn}/{id}_{condition}.pt',weights_only=False)\n",
    "    return X,y\n",
    "def load_snezana_mice(id):\n",
    "    X,y = torch.load(f'{path_to_pt_snezana_mice}/{id}.pt',weights_only=False)\n",
    "    return X,y\n",
    "\n",
    "class SimpleNorm(nn.Module):\n",
    "    def __init__(self,eps):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.tensor(1.0))\n",
    "        self.shift = nn.Parameter(torch.tensor(0.0))\n",
    "    def forward(self,x):\n",
    "        mean = x.flatten().mean()\n",
    "        std = x.flatten().std()\n",
    "        x = (x - mean) / (std + self.eps)\n",
    "        return x * self.scale + self.shift\n",
    "    \n",
    "class CNNSleepStager(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.norm = SimpleNorm(1e-5)\n",
    "        self.c1 = nn.Conv1d(in_channels=1,out_channels=4,kernel_size=7,padding='same')\n",
    "        self.c2 = nn.Conv1d(in_channels=4,out_channels=8,kernel_size=5,padding='same')\n",
    "        self.c3 = nn.Conv1d(in_channels=8,out_channels=16,kernel_size=3,padding='same')\n",
    "        self.c4 = nn.Conv1d(in_channels=16,out_channels=32,kernel_size=3,padding='same')\n",
    "\n",
    "        self.mp = nn.MaxPool1d(kernel_size=2)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=32,out_features=16)\n",
    "        self.classifier = nn.Linear(in_features=16,out_features=3)\n",
    "    def forward(self,x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        x = self.c1(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c2(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c3(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c4(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.gap(x)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    def get_latent_space(self,x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        x = self.c1(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c2(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c3(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c4(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.gap(x)\n",
    "        x = x.squeeze()\n",
    "        return x\n",
    "    \n",
    "model = CNNSleepStager()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "class EEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, id, condition):\n",
    "        self.X,self.y= load_ekyn(id=id,condition=condition)\n",
    "        self.X = self.X.unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "\n",
    "def compute_mmd(source, target, kernel_sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute MMD between source and target latent features using a Gaussian kernel.\n",
    "    Args:\n",
    "        source: Tensor of shape (batch_size, feature_dim), e.g., (32, 64)\n",
    "        target: Tensor of shape (batch_size, feature_dim), e.g., (32, 64)\n",
    "        kernel_sigma: Bandwidth of the Gaussian kernel\n",
    "    Returns:\n",
    "        MMD loss (scalar)\n",
    "    \"\"\"\n",
    "    # Number of samples\n",
    "    n_source = source.size(0)\n",
    "    n_target = target.size(0)\n",
    "\n",
    "    # Compute pairwise distances\n",
    "    xx = torch.cdist(source, source, p=2) ** 2  # Source-Source distances\n",
    "    yy = torch.cdist(target, target, p=2) ** 2  # Target-Target distances\n",
    "    xy = torch.cdist(source, target, p=2) ** 2  # Source-Target distances\n",
    "\n",
    "    # Gaussian kernel: exp(-distance^2 / sigma^2)\n",
    "    scale = 2 * (kernel_sigma ** 2)\n",
    "    k_xx = torch.exp(-xx / scale)\n",
    "    k_yy = torch.exp(-yy / scale)\n",
    "    k_xy = torch.exp(-xy / scale)\n",
    "\n",
    "    # MMD: mean of kernel terms\n",
    "    mmd = k_xx.mean() + k_yy.mean() - 2 * k_xy.mean()\n",
    "    return mmd\n",
    "\n",
    "traindataset = ConcatDataset([EEGDataset(id='A1-0',condition='PF')])\n",
    "testdataset  = ConcatDataset([EEGDataset(id='A1-1',condition='PF')])\n",
    "\n",
    "trainloader = DataLoader(traindataset, batch_size=512, shuffle=True)\n",
    "testloader = DataLoader(testdataset, batch_size=512, shuffle=True)\n",
    "\n",
    "Xi,yi = next(iter(trainloader))\n",
    "Xi.shape,yi.shape\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNSleepStager()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "lambda_mmd = 4  # Weight for MMD loss\n",
    "kernel_sigma = 1.0  # Gaussian kernel bandwidth\n",
    "num_epochs = 200\n",
    "lossi = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    trainiter = iter(trainloader)\n",
    "    testiter = iter(testloader)\n",
    "\n",
    "    total_loss = 0\n",
    "    num_batches = min(len(trainloader), len(testloader))\n",
    "\n",
    "    for _ in tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # Get batches\n",
    "        try:\n",
    "            source_x, source_y = next(trainiter)\n",
    "            target_x, _ = next(testiter)  # Ignore target labels for now\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        source_x, source_y = source_x.to(device), source_y.to(device)\n",
    "        target_x = target_x.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        source_logits = model(source_x)  # Predictions for classification\n",
    "        # source_latent = model.get_latent_space(source_x)  # Latent features\n",
    "        # target_latent = model.get_latent_space(target_x)  # Latent features\n",
    "\n",
    "        # Losses\n",
    "        ce_loss = criterion(source_logits, source_y)  # Cross-entropy on source\n",
    "        # mmd_loss = compute_mmd(source_latent, target_latent, kernel_sigma) * lambda_mmd  # MMD\n",
    "        # loss = ce_loss + mmd_lossv\n",
    "        loss = ce_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        lossi.append(loss.item())\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    # print(f\"Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}, CE: {ce_loss.item():.4f}, MMD: {mmd_loss.item():.4f}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lossi)\n",
    "    plt.savefig('loss.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "tsne = TSNE()\n",
    "Xi,yi = next(iter(trainloader))\n",
    "Xi,yi = Xi.to(device),yi.to(device)\n",
    "\n",
    "Xi_tsne = tsne.fit_transform(model.get_latent_space(Xi).detach().cpu())\n",
    "df = pd.DataFrame(torch.hstack([torch.from_numpy(Xi_tsne),yi.detach().cpu().argmax(dim=1,keepdim=True)]))\n",
    "sns.scatterplot(data=df,x=0,y=1,hue=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "tsne = TSNE()\n",
    "Xi,yi = next(iter(testloader))\n",
    "Xi,yi = Xi.to(device),yi.to(device)\n",
    "\n",
    "Xi_tsne = tsne.fit_transform(model.get_latent_space(Xi).detach().cpu())\n",
    "df = pd.DataFrame(torch.hstack([torch.from_numpy(Xi_tsne),yi.detach().cpu().argmax(dim=1,keepdim=True)]))\n",
    "sns.scatterplot(data=df,x=0,y=1,hue=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "tsne = TSNE()\n",
    "Xi,yi = next(iter(trainloader))\n",
    "Xi,yi = Xi.to(device),yi.to(device)\n",
    "Xi_tsne = tsne.fit_transform(model.get_latent_space(Xi).detach().cpu())\n",
    "df = pd.DataFrame(torch.hstack([torch.from_numpy(Xi_tsne),yi.detach().cpu().argmax(dim=1,keepdim=True)]))\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(data=df,x=0,y=1,hue=2,facecolors='none',marker='o')\n",
    "\n",
    "Xi,yi = next(iter(testloader))\n",
    "Xi,yi = Xi.to(device),yi.to(device)\n",
    "Xi_tsne = tsne.fit_transform(model.get_latent_space(Xi).detach().cpu())\n",
    "df = pd.DataFrame(torch.hstack([torch.from_numpy(Xi_tsne),yi.detach().cpu().argmax(dim=1,keepdim=True)]))\n",
    "sns.scatterplot(data=df,x=0,y=1,hue=2,marker='x',s=50,linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay,classification_report\n",
    "\n",
    "y = torch.vstack([torch.vstack([model(Xi.to(device)).softmax(dim=1).argmax(dim=1).detach().cpu(),yi.argmax(dim=1).detach().cpu()]).T for Xi,yi in trainloader])\n",
    "y_pred = y[:,0]\n",
    "y_true = y[:,1]\n",
    "print(classification_report(y_true=y_true,y_pred=y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)\n",
    "\n",
    "\n",
    "y = torch.vstack([torch.vstack([model(Xi.to(device)).softmax(dim=1).argmax(dim=1).detach().cpu(),yi.argmax(dim=1).detach().cpu()]).T for Xi,yi in testloader])\n",
    "y_pred = y[:,0]\n",
    "y_true = y[:,1]\n",
    "print(classification_report(y_true=y_true,y_pred=y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
