{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,ConcatDataset,TensorDataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score,classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def moving_average(data, window_size=10):\n",
    "    \"\"\"Compute the moving average of a list.\"\"\"\n",
    "    return np.convolve(data, np.ones(window_size), 'valid') / window_size\n",
    "\n",
    "class SleepStageClassifier(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.c1 = nn.Conv1d(in_channels=1,out_channels=64,kernel_size=3)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.fc1 = nn.Linear(in_features=64,out_features=3)\n",
    "    def forward(self,x):\n",
    "        x = self.c1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.flatten(1,2)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "def get_dataloaders():\n",
    "    X,y = torch.load(f'pt_ekyn_robust_50hz/A1-0_PF.pt')\n",
    "    X = X.unsqueeze(1)\n",
    "    dataset = TensorDataset(X,y)\n",
    "    labels = torch.argmax(y, dim=1)\n",
    "    class_counts = torch.bincount(labels)\n",
    "    num_classes = len(class_counts)\n",
    "    class_weights = 1. / class_counts.float()\n",
    "    weights = class_weights[labels]\n",
    "    trainloader = DataLoader(dataset, batch_size=32, sampler=WeightedRandomSampler(weights, num_samples=len(weights), replacement=True))\n",
    "\n",
    "    X,y = torch.load(f'pt_ekyn_robust_50hz/A1-1_Vehicle.pt')\n",
    "    X = X.unsqueeze(1)\n",
    "    dataset = TensorDataset(X,y)\n",
    "    labels = torch.argmax(y, dim=1)\n",
    "    class_counts = torch.bincount(labels)\n",
    "    num_classes = len(class_counts)\n",
    "    class_weights = 1. / class_counts.float()\n",
    "    weights = class_weights[labels]\n",
    "    testloader = DataLoader(dataset, batch_size=512, sampler=WeightedRandomSampler(weights, num_samples=len(weights), replacement=True))\n",
    "    return trainloader,testloader\n",
    "\n",
    "def evaluate(dataloader,model,criterion,device):\n",
    "    with torch.no_grad():\n",
    "        p = torch.vstack([torch.hstack([model(Xi.to(device)),yi.to(device)]) for Xi,yi in dataloader]).cpu()\n",
    "        p = torch.hstack([p,p[:,:3].softmax(dim=1).argmax(axis=1).unsqueeze(1)])\n",
    "        logits = p[:,:3]\n",
    "        y_true = p[:,3:6].argmax(axis=1)\n",
    "        y_pred = p[:,6:]\n",
    "        f1 = f1_score(y_true,y_pred,average='macro')\n",
    "        loss = criterion(logits,y_true).item()\n",
    "        report = classification_report(y_pred=y_pred,y_true=y_true,output_dict=True)\n",
    "    return loss,f1,report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_dir = 'data'\n",
    "device = 'mps'\n",
    "\n",
    "trainloader,testloader = get_dataloaders()\n",
    "model = SleepStageClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(),lr=3e-4,weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "trainlossi = []\n",
    "testlossi = []\n",
    "trainf1i = []\n",
    "trainf1p = []\n",
    "trainf1s = []\n",
    "trainf1w = []\n",
    "testf1i = []\n",
    "testf1p = []\n",
    "testf1s = []\n",
    "testf1w = []\n",
    "best_dev_loss = torch.inf\n",
    "best_dev_loss_epoch = 0\n",
    "best_dev_f1 = 0\n",
    "best_dev_f1_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 173/1000 [04:06<20:22,  1.48s/it]"
     ]
    }
   ],
   "source": [
    "window_size = 10\n",
    "for epoch in tqdm(range(1000)):\n",
    "    for Xi, yi in trainloader:\n",
    "        Xi, yi = Xi.to(device), yi.to(device)\n",
    "        logits = model(Xi)\n",
    "        loss = criterion(logits, yi)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate\n",
    "    loss, f1, report = evaluate(trainloader, model, criterion, device)\n",
    "    trainlossi.append(loss)\n",
    "    trainf1i.append(report['macro avg']['f1-score'])\n",
    "    trainf1p.append(report['0']['f1-score'])\n",
    "    trainf1s.append(report['1']['f1-score'])\n",
    "    trainf1w.append(report['2']['f1-score'])\n",
    "    \n",
    "    loss, f1, report = evaluate(testloader, model, criterion, device)\n",
    "    testlossi.append(loss)\n",
    "    testf1i.append(report['macro avg']['f1-score'])\n",
    "    testf1p.append(report['0']['f1-score'])\n",
    "    testf1s.append(report['1']['f1-score'])\n",
    "    testf1w.append(report['2']['f1-score'])\n",
    "\n",
    "    # Update best models\n",
    "    if testlossi[-1] < best_dev_loss:\n",
    "        torch.save(model.state_dict(), 'model_bestdevloss.pt')\n",
    "        best_dev_loss = testlossi[-1]\n",
    "        best_dev_loss_epoch = epoch\n",
    "    if testf1i[-1] > best_dev_f1:\n",
    "        torch.save(model.state_dict(), 'model_bestdevf1.pt')\n",
    "        best_dev_f1 = testf1i[-1]\n",
    "        best_dev_f1_epoch = epoch\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(6,10))\n",
    "\n",
    "    # Define colors for train and test\n",
    "    train_color = '#1f77b4'\n",
    "    test_color = '#ff7f0e'\n",
    "\n",
    "    # First subplot - Loss\n",
    "    ax[0].plot(trainlossi, label='Train Loss', color=train_color, alpha=0.4)\n",
    "    ax[0].plot(testlossi, label='Test Loss', color=test_color, alpha=0.4)\n",
    "    # Moving average for loss\n",
    "    if len(trainlossi) > window_size:\n",
    "        ax[0].plot(range(window_size-1, len(trainlossi)), moving_average(trainlossi, window_size), label='Train Loss MA', color=train_color, linestyle='--')\n",
    "    if len(testlossi) > window_size:\n",
    "        ax[0].plot(range(window_size-1, len(testlossi)), moving_average(testlossi, window_size), label='Test Loss MA', color=test_color, linestyle='--')\n",
    "    ax[0].axhline(best_dev_loss, color='r', linestyle=':')\n",
    "    ax[0].axvline(best_dev_loss_epoch, color='r', linestyle=':')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Second subplot - F1 Score\n",
    "    ax[1].plot(trainf1i, label='Train F1', color=train_color, alpha=0.4)\n",
    "    ax[1].plot(testf1i, label='Test F1', color=test_color, alpha=0.4)\n",
    "    # Moving average for F1\n",
    "    if len(trainf1i) > window_size:\n",
    "        ax[1].plot(range(window_size-1, len(trainf1i)), moving_average(trainf1i, window_size), label='Train F1 MA', color=train_color, linestyle='--')\n",
    "    if len(testf1i) > window_size:\n",
    "        ax[1].plot(range(window_size-1, len(testf1i)), moving_average(testf1i, window_size), label='Test F1 MA', color=test_color, linestyle='--')\n",
    "    ax[1].axhline(best_dev_f1, color='r', linestyle=':')\n",
    "    ax[1].axvline(best_dev_f1_epoch, color='r', linestyle=':')\n",
    "    ax[1].legend()\n",
    "\n",
    "    # Third subplot - F1 Scores by class\n",
    "    labels = ['Paradoxical', 'Slow Wave', 'Wakefulness']\n",
    "    for i, (train, test, label) in enumerate(zip([trainf1p, trainf1s, trainf1w], [testf1p, testf1s, testf1w], labels)):\n",
    "        # ax[2].plot(train, label=f'{label} (Train)', color=train_color, linestyle='-', alpha=0.4)\n",
    "        # ax[2].plot(test, label=f'{label} (Test)', color=test_color, linestyle='--', alpha=0.4)\n",
    "        # Moving average for each class\n",
    "        if len(train) > window_size:\n",
    "            ax[2].plot(range(window_size-1, len(train)), moving_average(train, window_size), color=train_color, linestyle='-.')\n",
    "        if len(test) > window_size:\n",
    "            ax[2].plot(range(window_size-1, len(test)), moving_average(test, window_size), color=test_color, linestyle=':')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('loss_with_ma.jpg')\n",
    "    plt.close()\n",
    "    \n",
    "    torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
